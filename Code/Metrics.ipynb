{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import javalang\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mv_0jvZX73ft"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/NonFullContext-Result.csv',index_col='index')"
      ],
      "metadata": {
        "id": "ZYQzyBhH5ILW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein(seq1, seq2):\n",
        "    \n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "                \n",
        "    return (matrix[size_x - 1, size_y - 1])\n",
        "\n",
        "\n",
        "def levenshtein_normalized(seq1, seq2):\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "    return matrix[size_x - 1, size_y - 1]/max(size_x, size_y)"
      ],
      "metadata": {
        "id": "AC-gVGQ04OGf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = list(df['body'])\n",
        "original = list(df['generatedResultOriginal'])\n",
        "perturbated0 = list(df['generatedResultP0'])\n",
        "perturbated1 = list(df['generatedResultP1'])\n",
        "perturbated2 = list(df['generatedResultP2'])\n",
        "\n",
        "resultOriginalMethods = list(df['mvnTestResultOriginal'])\n",
        "resultP0Methods = list(df['mvnTestResultP0'])\n",
        "resultP1Methods = list(df['mvnTestResultP1'])\n",
        "resultP2Methods = list(df['mvnTestResultP2'])\n",
        "\n",
        "\n",
        "###############################################\n",
        "\n",
        "originalJavaDoc = list(df['javaDocFirstSentence'])\n",
        "perturbatedJavaDoc0 = []\n",
        "perturbatedJavaDoc1 = []\n",
        "perturbatedJavaDoc2 = []\n",
        "for item in df['perturbatedJavaDocSentence']:\n",
        "  item = eval(item)\n",
        "  perturbatedJavaDoc0.append(item[0])\n",
        "  perturbatedJavaDoc1.append(item[1])\n",
        "  perturbatedJavaDoc2.append(item[2])"
      ],
      "metadata": {
        "id": "_0RLlbGq5MaE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lev distance computation for code\n",
        "\n",
        "levDistanceTargetOriginal = []\n",
        "levDistanceTargetP0 = []\n",
        "levDistanceTargetP1 = []\n",
        "levDistanceTargetP2 = []\n",
        "levDistanceTargetOriginalNorm = []\n",
        "levDistanceTargetP0Norm = []\n",
        "levDistanceTargetP1Norm = []\n",
        "levDistanceTargetP2Norm = []\n",
        "\n",
        "levDistanceOriginalP0 = []\n",
        "levDistanceOriginalP1 = []\n",
        "levDistanceOriginalP2 = []\n",
        "levDistanceOriginalP0Norm = []\n",
        "levDistanceOriginalP1Norm = []\n",
        "levDistanceOriginalP2Norm = []\n",
        "\n",
        "for (targetMethod, originalMethod, perturbated0Method, perturbated1Method, perturbated2Method, resultOriginalMethod, resultP0Method, resultP1Method, resultP2Method) in tqdm(zip(target, original, perturbated0, perturbated1, perturbated2, resultOriginalMethods, resultP0Methods, resultP1Methods, resultP2Methods)):\n",
        "\n",
        "  originalBodyTokens = []\n",
        "  targetBodyTokens = []\n",
        "\n",
        "  if originalMethod == 'Empty Method' or resultOriginalMethod == 'Not Valid' or resultOriginalMethod == 'Syntax Error':\n",
        "      \n",
        "      # levDistanceOriginalP0.append('None')\n",
        "      # levDistanceOriginalP0Norm.append('None')\n",
        "\n",
        "      # levDistanceOriginalP1.append('None')\n",
        "      # levDistanceOriginalP1Norm.append('None')\n",
        "      \n",
        "      # levDistanceOriginalP2.append('None')\n",
        "      # levDistanceOriginalP2Norm.append('None')\n",
        "\n",
        "      levDistanceTargetOriginal.append('None')\n",
        "      levDistanceTargetOriginalNorm.append('None')\n",
        "     \n",
        "  \n",
        "  else:\n",
        "    originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "    targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "    lev = levenshtein(originalBodyTokens, targetBodyTokens)\n",
        "    levDistanceTargetOriginal.append(lev)\n",
        "\n",
        "    levNorm = levenshtein_normalized(originalBodyTokens, targetBodyTokens)\n",
        "    levDistanceTargetOriginalNorm.append(levNorm)\n",
        "\n",
        "  ##################################################################################################\n",
        "  \n",
        "  if perturbated0Method == 'Empty Method' or resultP0Method == 'Not Valid' or resultP0Method == 'Syntax Error':\n",
        "    \n",
        "    levDistanceOriginalP0.append('None')\n",
        "    levDistanceOriginalP0Norm.append('None')\n",
        "\n",
        "    levDistanceTargetP0.append('None')\n",
        "    levDistanceTargetP0Norm.append('None')\n",
        "  \n",
        "  else:\n",
        "    try:\n",
        "      originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "      p0BodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbated0Method))]\n",
        "      targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "      lev = levenshtein(originalBodyTokens, p0BodyTokens)\n",
        "      levDistanceOriginalP0.append(lev)\n",
        "\n",
        "      levNorm = levenshtein_normalized(originalBodyTokens, p0BodyTokens)\n",
        "      levDistanceOriginalP0Norm.append(levNorm)\n",
        "\n",
        "      lev = levenshtein(targetBodyTokens, p0BodyTokens)\n",
        "      levDistanceTargetP0.append(lev)\n",
        "\n",
        "      levNorm = levenshtein_normalized(targetBodyTokens, p0BodyTokens)\n",
        "      levDistanceTargetP0Norm.append(levNorm)\n",
        "\n",
        "    except Exception:\n",
        "      \n",
        "      levDistanceOriginalP0.append('None')\n",
        "      levDistanceOriginalP0Norm.append('None')\n",
        "\n",
        "      levDistanceTargetP0.append('None')\n",
        "      levDistanceTargetP0Norm.append('None')\n",
        "\n",
        "  ##################################################################################################\n",
        "\n",
        "  if perturbated1Method == 'Empty Method' or resultP1Method == 'Not Valid' or perturbated1Method == 'Syntax Error':\n",
        "      \n",
        "      levDistanceOriginalP1.append('None')\n",
        "      levDistanceOriginalP1Norm.append('None')\n",
        "\n",
        "      levDistanceTargetP1.append('None')\n",
        "      levDistanceTargetP1Norm.append('None')\n",
        "\n",
        "  else:          \n",
        "      try:\n",
        "        originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "        p1BodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbated1Method))]\n",
        "        targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "        lev = levenshtein(originalBodyTokens, p1BodyTokens)\n",
        "        levDistanceOriginalP1.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(originalBodyTokens, p1BodyTokens)\n",
        "        levDistanceOriginalP1Norm.append(levNorm)\n",
        "\n",
        "        lev = levenshtein(targetBodyTokens, p1BodyTokens)\n",
        "        levDistanceTargetP1.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(targetBodyTokens, p1BodyTokens)\n",
        "        levDistanceTargetP1Norm.append(levNorm)\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "\n",
        "        levDistanceOriginalP1.append('None')\n",
        "        levDistanceOriginalP1Norm.append('None')\n",
        "\n",
        "        levDistanceTargetP1.append('None')\n",
        "        levDistanceTargetP1Norm.append('None')\n",
        "\n",
        "  ##################################################################################################\n",
        "  if perturbated2Method == 'Empty Method' or resultP2Method == 'Not Valid' or perturbated2Method == 'Syntax Error':\n",
        "      \n",
        "      levDistanceOriginalP2.append('None')\n",
        "      levDistanceOriginalP2Norm.append('None')\n",
        "\n",
        "      levDistanceTargetP2.append('None')\n",
        "      levDistanceTargetP2Norm.append('None')\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "        originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "        p2BodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbated2Method))]\n",
        "        targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "        lev = levenshtein(originalBodyTokens, p2BodyTokens)\n",
        "        levDistanceOriginalP2.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(originalBodyTokens, p2BodyTokens)\n",
        "        levDistanceOriginalP2Norm.append(levNorm)\n",
        "\n",
        "        lev = levenshtein(targetBodyTokens, p2BodyTokens)\n",
        "        levDistanceTargetP2.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(targetBodyTokens, p2BodyTokens)\n",
        "        levDistanceTargetP2Norm.append(levNorm)\n",
        "\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "        \n",
        "        levDistanceOriginalP2.append('None')\n",
        "        levDistanceOriginalP2Norm.append('None')\n",
        "        \n",
        "        levDistanceTargetP2.append('None')\n",
        "        levDistanceTargetP2Norm.append('None')\n",
        "  ##################################################################################################\n",
        "\n",
        "\n",
        "len(levDistanceOriginalP0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MRJbXpyV-jKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Lev distance computation for javadoc\n",
        "\n",
        "levDistanceOriginalJavaDocP0 = []\n",
        "levDistanceOriginalJavaDocP1 = []\n",
        "levDistanceOriginalJavaDocP2 = []\n",
        "\n",
        "levDistanceOriginalJavaDocP0Norm = []\n",
        "levDistanceOriginalJavaDocP1Norm = []\n",
        "levDistanceOriginalJavaDocP2Norm = []\n",
        "\n",
        "for (javaDocOriginal, javaDocP0, javaDocP1, javaDocP2) in tqdm(zip(originalJavaDoc, perturbatedJavaDoc0, perturbatedJavaDoc1, perturbatedJavaDoc2)):\n",
        "\n",
        "    levDistanceOriginalJavaDocP0.append(levenshtein(javaDocOriginal.split(), javaDocP0.split()))\n",
        "    levDistanceOriginalJavaDocP0Norm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocP0.split()))\n",
        "\n",
        "    levDistanceOriginalJavaDocP1.append(levenshtein(javaDocOriginal.split(), javaDocP1.split()))\n",
        "    levDistanceOriginalJavaDocP1Norm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocP1.split()))\n",
        "    \n",
        "    levDistanceOriginalJavaDocP2.append(levenshtein(javaDocOriginal.split(), javaDocP2.split()))\n",
        "    levDistanceOriginalJavaDocP2Norm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocP2.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmpBYNXmBbx-",
        "outputId": "6859eff2-842b-4c72-c0e1-d03cd04c9fca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1006it [00:02, 498.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codeBleuAgainstOriginal = []\n",
        "codeBleuAgainstP0 = []\n",
        "codeBleuAgainstP1 = []\n",
        "codeBleuAgainstP2 = []\n",
        "\n",
        "\n",
        "for (targetMethod, originalMethod, perturbated0Method, perturbated1Method, perturbated2Method, resultOriginalMethod, resultP0Method, resultP1Method, resultP2Method) in tqdm(zip(target, original, perturbated0, perturbated1, perturbated2, resultOriginalMethods, resultP0Methods, resultP1Methods, resultP2Methods)):\n",
        "\n",
        "  if originalMethod == 'Empty Method' or resultOriginalMethod == 'Not Valid' or resultOriginalMethod == 'Syntax Error':\n",
        "      codeBleuAgainstOriginal.append('None')\n",
        "  else:\n",
        "      \n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          originalBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(originalMethod))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          \n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(originalBodyTokens)\n",
        "          \n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "        \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "        \n",
        "          codeBleuAgainstOriginal.append('{}'.format(codeBleuScore))\n",
        "      \n",
        "      except Exception:\n",
        "        codeBleuAgainstOriginal.append('None')\n",
        "        \n",
        "\n",
        "  if perturbated0Method == 'Empty Method' or resultP0Method == 'Not Valid' or resultP0Method == 'Syntax Error':\n",
        "      codeBleuAgainstP0.append('None')\n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          p0BodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbated0Method))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(p0BodyTokens)\n",
        "          \n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "      \n",
        "          infoScore = res[0]\n",
        "\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "\n",
        "          codeBleuAgainstP0.append('{}'.format(codeBleuScore))\n",
        "\n",
        "      except Exception:\n",
        "        codeBleuAgainstP0.append('None')\n",
        "        \n",
        "\n",
        "  if perturbated1Method == 'Empty Method' or resultP1Method == 'Not Valid' or resultP1Method == 'Syntax Error':\n",
        "      codeBleuAgainstP1.append('None')\n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          p1BodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbated1Method))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(p1BodyTokens)\n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "      \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "      \n",
        "          codeBleuAgainstP1.append('{}'.format(codeBleuScore))\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "          codeBleuAgainstP1.append('None')\n",
        "      \n",
        "  if perturbated2Method == 'Empty Method' or resultP2Method == 'Not Valid' or resultP2Method == 'Syntax Error':\n",
        "      codeBleuAgainstP2.append('None')\n",
        "  \n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          p2BodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbated2Method))])\n",
        "      \n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(p2BodyTokens)\n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "          \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "          codeBleuAgainstP2.append('{}'.format(codeBleuScore))\n",
        "      \n",
        "      except Exception:\n",
        "          codeBleuAgainstP2.append('None')\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "     "
      ],
      "metadata": {
        "id": "g-oAZVG7513E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CodeBleuOriginal'] = codeBleuAgainstOriginal\n",
        "df['CodeBleuP0'] = codeBleuAgainstP0\n",
        "df['CodeBleuP1'] = codeBleuAgainstP1\n",
        "df['CodeBleuP2'] = codeBleuAgainstP2\n",
        "\n",
        "df['levenshteinTarget-Original-Code'] =  levDistanceTargetOriginal\n",
        "df['levenshteinTarget-Original-Code-Normalized'] =  levDistanceTargetOriginalNorm\n",
        "\n",
        "df['levenshteinTarget-P0-Code'] =  levDistanceTargetP0\n",
        "df['levenshteinTarget-P0-Code-Normalized'] =  levDistanceTargetP0Norm\n",
        "\n",
        "df['levenshteinTarget-P1-Code'] =  levDistanceTargetP1\n",
        "df['levenshteinTarget-P1-Code-Normalized'] =  levDistanceTargetP1Norm\n",
        "\n",
        "df['levenshteinTarget-P2-Code'] =  levDistanceTargetP2\n",
        "df['levenshteinTarget-P2-Code-Normalized'] =  levDistanceTargetP2Norm\n",
        "\n",
        "######################################################################\n",
        "\n",
        "\n",
        "df['levenshteinOriginal-P0-Code'] = levDistanceOriginalP0\n",
        "df['levenshteinOriginal-P0-Code-Normalized'] = levDistanceOriginalP0Norm\n",
        "\n",
        "df['levenshteinOriginal-P1-Code'] = levDistanceOriginalP1\n",
        "df['levenshteinOriginal-P1-Code-Normalized'] = levDistanceOriginalP1Norm\n",
        "\n",
        "\n",
        "df['levenshteinOriginal-P2-Code'] = levDistanceOriginalP2\n",
        "df['levenshteinOriginal-P2-Code-Normalized'] = levDistanceOriginalP2Norm\n",
        "\n",
        "######################################################################\n",
        "\n",
        "df['levenshteinOriginal-P0-JavaDoc'] = levDistanceOriginalJavaDocP0\n",
        "df['levenshteinOriginal-P0-JavaDoc-Normalized'] = levDistanceOriginalJavaDocP0Norm\n",
        "\n",
        "df['levenshteinOriginal-P1-JavaDoc'] = levDistanceOriginalJavaDocP1\n",
        "df['levenshteinOriginal-P1-JavaDoc-Normalized'] = levDistanceOriginalJavaDocP1Norm\n",
        "\n",
        "df['levenshteinOriginal-P2-JavaDoc'] = levDistanceOriginalJavaDocP2\n",
        "df['levenshteinOriginal-P2-JavaDoc-Normalized'] = levDistanceOriginalJavaDocP2Norm\n",
        "\n"
      ],
      "metadata": {
        "id": "Gui9LMgE4B6j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('Non-FullContext-Result1.csv')"
      ],
      "metadata": {
        "id": "7a_CX4e7aG3n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fr4PjBidKgEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}